# ---------------------------------------------------------------------------
# Usenet Media Stack - Environment Template
# Copy to .env and adjust for your host/cluster.
# ---------------------------------------------------------------------------

# Identity / perms
PUID=1000
PGID=1000
TZ=Etc/UTC

# NOTE: .env is parsed as plain key=value (no command substitution).
# Use literal values (no $(cat ...) or backticks).

# Domain for Traefik routes (used by swarm compose)
DOMAIN=example.com

# Usenet providers (primary required for full stack)
NEWSHOSTING_USER=
NEWSHOSTING_PASS=
NEWSHOSTING_SERVER=news.newshosting.com
NEWSHOSTING_PORT=563
NEWSHOSTING_CONNECTIONS=30
# Optional secondary providers
USENETEXPRESS_USER=
USENETEXPRESS_PASS=
USENETEXPRESS_SERVER=usenetexpress.com
USENETEXPRESS_PORT=563
USENETEXPRESS_CONNECTIONS=20
FRUGAL_USER=
FRUGAL_PASS=
FRUGAL_SERVER=newswest.frugalusenet.com
FRUGAL_PORT=563
FRUGAL_CONNECTIONS=10

# Indexers (at least one required)
NZBGEEK_API=
NZBFINDER_API=
NZBSU_API=
NZBPLANET_API=

# =============================================================================
# Storage Paths (Critical Architecture Decision)
# =============================================================================
#
# IMPORTANT: For MergerFS/multi-disk setups, put DOWNLOADS on the SAME pool
# as your final media destination. This enables instant hardlink/mv operations
# (inode change only, no data copy) instead of forcing double I/O.
#
# Example architectures:
#
# Single Disk:
#   DOWNLOADS_ROOT=/srv/usenet/downloads
#   MEDIA_ROOT=/srv/usenet/media
#
# MergerFS Pool (recommended for multi-disk):
#   POOL_ROOT=/var/mnt/pool              # Union mount of multiple drives
#   DOWNLOADS_ROOT=/var/mnt/pool/downloads  # Downloads on pool = instant mv
#   MEDIA_ROOT=/var/mnt/pool              # Container maps /pool â†’ pool root
#   # Final paths: /pool/movies, /pool/tv, /pool/anime
#
# Why this matters:
# - Downloads on separate disk = full file copy when Sonarr/Radarr imports
# - Downloads on same pool = instant inode change (btrfs/ext4 reflink)
# - With parallel encoding, separate disks waste CPU and double disk I/O
# =============================================================================

CONFIG_ROOT=/srv/usenet/config
DOWNLOADS_ROOT=/srv/usenet/downloads
MEDIA_ROOT=/srv/usenet/media

# Pool root (for MergerFS or multi-disk setups)
# Containers mount this as /pool for unified access to /pool/movies, /pool/tv, etc.
POOL_ROOT=/var/mnt/pool

# Reading/library roots (optional but recommended)
BOOKS_ROOT=/srv/usenet/books
COMICS_ROOT=/srv/usenet/books/Comics
EBOOKS_ROOT=/srv/usenet/books/eBooks
AUDIOBOOKS_ROOT=/srv/usenet/books/Audiobooks
PODCASTS_ROOT=/srv/usenet/books/Podcasts

# Repo root (used to serve docs via usenet-docs nginx)
STACK_ROOT=${HOME:-/home/deck}/Documents/Code/media-automation/usenet-media-stack

# =============================================================================
# Example: Bazzite/Steam Deck NUC with MergerFS (41TB pool)
# =============================================================================
#
# ARCHITECTURE: Portable (internal NVMe) vs Pool (home-theater) split
#
# Internal NVMe (fast8tb) - Portable content for travel with NUC:
# - ROMs/emulators, books, audiobooks, comics/manga
# - Survives when external drives are disconnected
#
# Pool (MergerFS) - Heavy home-theater content:
# - Films, TV series, anime (films + TV)
# - Downloads (for instant mv to pool destinations)
#
# CONFIG_ROOT=/var/mnt/fast8tb/config           # App configs (internal)
# DOWNLOADS_ROOT=/var/mnt/pool/downloads        # ON POOL for instant mv
# POOL_ROOT=/var/mnt/pool                       # 41TB MergerFS union
# BOOKS_ROOT=/var/mnt/fast8tb/Cloud/OneDrive/Books      # Portable (internal)
# COMICS_ROOT=/var/mnt/fast8tb/Cloud/OneDrive/Books/Comics  # Portable (internal)

# NFS export for multi-node swarm (used by docker-compose.swarm.yml)
# If you use the local-bind override, these can stay commented.
# NFS_SERVER=10.0.0.10
# NFS_PATH=/srv/usenet

# Stack name (optional convenience)
STACK_NAME=usenet
# Root of music library (Lidarr)
MUSIC_ROOT=/srv/usenet/media/music
# Komf config dir (optional override; defaults to CONFIG_ROOT/komf)
KOMF_CONFIG=/srv/usenet/config/komf
# Komga config/tmp (optional overrides)
KOMGA_CONFIG=/srv/usenet/config/komga
KOMGA_TMP=/srv/usenet/config/komga/tmp
# Audiobookshelf config dir (optional override; defaults to CONFIG_ROOT/audiobookshelf)
AUDIOBOOKSHELF_CONFIG=/srv/usenet/config/audiobookshelf
# Kometa config dir (optional)
KOMETA_CONFIG=/srv/usenet/config/kometa
# Aria2 RPC secret (set a strong value; required for aria2 JSON-RPC)
ARIA2_SECRET=changeme
# Plex claim token (optional; required on first Plex setup)
PLEX_CLAIM=

# Mullvad (WireGuard via gluetun)
MULLVAD_ACCOUNT=
# WireGuard keys/addresses for gluetun (do not commit real values)
MULLVAD_WG_PRIVATE_KEY=
MULLVAD_WG_ADDRESSES=10.69.163.158/32
# Optional overrides (defaults: USA / New York NY)
MULLVAD_COUNTRY=USA
MULLVAD_CITY="New York NY"
# MULLVAD_HOSTNAME=us-nyc-001
# MULLVAD_HOSTNAME=us-nyc-001

# Mylar / Komga helpers
MYLAR_API_KEY=
KOMF_COMICVINE_API_KEY=
KOMF_ANILIST_CLIENT_ID=
KOMF_ANILIST_CLIENT_SECRET=
KOMF_MANGAUPDATES_USERNAME=
KOMF_MANGAUPDATES_PASSWORD=
KOMF_MANGADEX_CLIENT_ID=
KOMF_MANGADEX_CLIENT_SECRET=
MYLAR_COMICVINE_API_KEY=
# Lidarr helper
LIDARR_API_KEY=

# =============================================================================
# HARDWARE-SPECIFIC CONFIGURATION
# =============================================================================
# Document your machine specs here, then tune resource limits accordingly.
# This section is critical for portability - change values per machine.
#
# Example machine (Steam Deck Desktop / NUC):
# - CPU: AMD Ryzen 7 7840HS (16 threads) @ 4.6GHz
# - RAM: 96GB DDR5
# - GPU: AMD Radeon 780M (RDNA3, 16GB shared, VAAPI support)
# - Storage: 8TB NVMe (fast8tb) + 41TB MergerFS pool (4x external drives)
#
# Your machine:
# - CPU: [your CPU model]
# - RAM: [your RAM amount]
# - GPU: [your GPU model, note if VAAPI/NVENC/QSV supported]
# - Storage: [your storage layout]

# -----------------------------------------------------------------------------
# Tdarr Resource Limits
# -----------------------------------------------------------------------------
# Main server (handles orchestration + internal node)
TDARR_MAIN_CPU_LIMIT=4.0
TDARR_MAIN_MEM_LIMIT=8G
TDARR_MAIN_CPU_RESERVE=2.0
TDARR_MAIN_MEM_RESERVE=4G

# Secondary node (for parallel transcoding)
TDARR_NODE_CPU_LIMIT=4.0
TDARR_NODE_MEM_LIMIT=8G

# -----------------------------------------------------------------------------
# Tdarr Worker Configuration
# -----------------------------------------------------------------------------
# GPU workers: VAAPI (AMD), NVENC (NVIDIA), or QSV (Intel) - fast, low power
# CPU workers: Fallback for unsupported codecs or when GPU busy
# Recommendation: Enable BOTH for flexibility (some transcodes need CPU)
#
# Main node workers:
TDARR_TRANSCODE_GPU_WORKERS=4
TDARR_TRANSCODE_CPU_WORKERS=2
TDARR_HEALTHCHECK_GPU_WORKERS=1
TDARR_HEALTHCHECK_CPU_WORKERS=1

# Secondary node workers:
TDARR_NODE_TRANSCODE_GPU_WORKERS=2
TDARR_NODE_TRANSCODE_CPU_WORKERS=2
TDARR_NODE_HEALTHCHECK_GPU_WORKERS=1
TDARR_NODE_HEALTHCHECK_CPU_WORKERS=1

# -----------------------------------------------------------------------------
# GPU Passthrough
# -----------------------------------------------------------------------------
# The docker-compose passes /dev/dri to containers for hardware encoding.
# This works for AMD (VAAPI) and Intel (QSV) GPUs.
#
# For NVIDIA GPUs, you'll need to:
# 1. Install nvidia-container-toolkit
# 2. Use runtime: nvidia or deploy.resources.reservations.devices in compose
# 3. Set NVIDIA_VISIBLE_DEVICES=all
#
# For CPU-only transcoding (no GPU), set:
# TDARR_TRANSCODE_GPU_WORKERS=0
# TDARR_TRANSCODE_CPU_WORKERS=4  # Adjust based on CPU cores
# TDARR_NODE_TRANSCODE_GPU_WORKERS=0
# TDARR_NODE_TRANSCODE_CPU_WORKERS=2

# -----------------------------------------------------------------------------
# General *arr App Resources
# -----------------------------------------------------------------------------
ARR_CPU_LIMIT=1.0
ARR_MEM_LIMIT=4G

# Plex resources
PLEX_CPU_LIMIT=2.0
PLEX_MEM_LIMIT=4G
